% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/performance.R
\name{mean_squared_log_error}
\alias{mean_squared_log_error}
\title{Mean Squared Logarithmic Error}
\usage{
mean_squared_log_error(
  true,
  pred,
  weights = NULL,
  multi = c("average", "sum", "raw"),
  root = FALSE,
  rweights = NULL
)
}
\arguments{
\item{true}{a vector (or a matrix) of observed values. If a matrix is provided,
a multi-response is assumed}

\item{pred}{a vector (or a matrix) of predicted values}

\item{weights}{observation weights}

\item{multi}{what to do when response has multiple output values
\describe{
\item{\code{average}}{errors of multiple outputs are averaged to get a single value for each observation}
\item{\code{sum}}{errors of multiple outputs are summed up to get a single value for each observation}
\item{\code{raw}}{returns a vector containing one error for each output}
}}

\item{root}{logical, whether to return the MSLE or the root mean squared logarithmic error (RMSLE)}

\item{rweights}{response weights}
}
\value{
the mean squared error, a positive \code{double} or a vector of positive \code{double} values,
one for each response, if response has multiple output values and \code{multi = "raw"}
}
\description{
This function computes the mean squared logarithmic error.
}
\details{
The mean squared logarithmic error (MSLE) is a measure of errors based on squared
logarithmic losses. This metric is commonly preferred (e.g. over the MSE) when
\itemize{
\item Under-predicted estimates are more penalised than over-predicted ones.
\item Huge differences in the predicted and true values aren't to be penalised (when both are huge numbers).
}

The MSLE estimated over n observations is defined as

\deqn{MSLE(y,\hat{y}) = \frac{1}{n}\sum_{i=1}^{n} (log(1 + y_{i}) - log(1 + \hat{y}_{i}))^{2}}

where \eqn{log} is the natural logarithm, \eqn{y_{i}} is the true value of the \eqn{i}-th sample
and \eqn{\hat{y}_{i}} is the predicted value.
If observation weights are provided, then the weighted mean absolute error is computed as

\deqn{wMSLE(w,y,\hat{y}) = \frac{1}{\sum_{i=1}^{n} w_{i}}\sum_{i=1}^{n} w_{i} * (log(1 + y_{i}) - log(1 + \hat{y}_{i}))^{2}}

where \eqn{w_{i}} is the weighting factor assigned to the \eqn{i}-th observation.

The best possible score is zero.
}
\author{
Alessandro Barberis
}
